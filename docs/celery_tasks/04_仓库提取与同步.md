# 04｜仓库提取与同步（Extract vs Sync）

这部分有两条相关链路：

1. **Extract（从文章里提取仓库）**：面向“文章内容”。
2. **Sync（同步 GitHub Star 仓库）**：面向“用户的仓库列表”。

核心代码：
- `backend/app/celery_app/repo_extractor.py`
- `backend/app/celery_app/repository_tasks.py`

---

## A. 文章仓库提取：extract_article_repos

触发方式：

- 主链路：`process_article_rag` 成功后自动调度 `extract_article_repos`
- 兜底：Beat 每 30 分钟 `scan_pending_repo_extraction` 扫描 `repos_extracted is null` 的文章并补跑

### extract_article_repos 的内部顺序（高层）

实际工作在 `do_extract_article_repos(article_id, user_id)`：

1. 读取文章 `content/summary`
2. 从 HTML/文本里提取显式 GitHub 链接（规则提取）
3. 可选：用 AI 提取“隐式仓库”（需要用户有 chat 配置）
4. 合并去重，限制最多 20 个仓库
5. 获取用户 GitHub token（settings.github_token）
6. 对每个仓库：
   - 数据库已存在：复用
   - 不存在：请求 GitHub API → upsert 到 `repositories`
7. 写入文章-仓库关联表（bulk link）
8. 标记文章 `repos_extracted = true/false`
9. 如果本次确实新建了仓库：触发 `_maybe_trigger_sync(user_id)`

### _maybe_trigger_sync：提取后触发同步（合并触发）

为了避免多篇文章同时触发大量 sync：

- 用 Redis 锁 `trigger_sync_after_extract:{user_id}` 做 60 秒去重
- 延迟 30 秒调度 `sync_repositories(user_id, trigger="auto")`

---

## B. Star 仓库同步：sync_repositories

触发方式：

- 自动：上一次 sync 结束后，会 `schedule_next_repo_sync`，1 小时后再跑
- 手动：前端“Sync repositories”按钮触发（当前走的是后端 SSE 版本，不是 Celery task）
- 间接：文章仓库提取后，可能触发一次 sync（见上）

### sync_repositories 的内部顺序（高层）

1. 获取锁：`repo_sync:{user_id}`（TTL=11min）
2. 读取用户 GitHub token（没有则直接失败返回）
3. `do_sync_repositories`：
   - 拉取 GitHub Star 列表（分页）
   - 只对“新仓库 / pushed_at 变更 / 缺 README”的仓库抓 README
   - 同时也会补抓“从文章提取但不在 Star 里”的仓库 README
   - upsert 到 `repositories`
4. AI 分析（可选/容错）：为需要分析的仓库生成 summary/tags/platforms
5. OpenRank 更新（可选/容错）：批量抓 openrank
6. 仓库 embeddings（可选/容错）：把仓库文本分块并生成向量
7. 调度下一次 sync：`schedule_next_repo_sync`（1 小时后）
8. 释放锁

---

## C. “Extract”和“Sync”区别一句话版

- **extract_article_repos**：从文章内容找到仓库，并把“文章 ↔ 仓库”关联建起来。
- **sync_repositories**：以 GitHub Star 为权威来源，同步仓库列表/README，并做 AI/指标/向量。

