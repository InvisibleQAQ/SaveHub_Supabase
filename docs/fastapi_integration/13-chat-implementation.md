# Chat åŠŸèƒ½å®ç°ï¼ˆæ— çŠ¶æ€è®¾è®¡ï¼‰

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•åœ¨ FastAPI åç«¯å®ç°æ— çŠ¶æ€ Chat åŠŸèƒ½ï¼ŒåŒ…æ‹¬ API ç«¯ç‚¹ã€Langchain é›†æˆå’Œæµå¼å“åº”ã€‚

**è®¾è®¡å†³ç­–**: Chat é‡‡ç”¨**æ— çŠ¶æ€è®¾è®¡**ï¼Œä¸å­˜å‚¨èŠå¤©è®°å½•åˆ°æ•°æ®åº“ã€‚èŠå¤©å†å²ç”±å‰ç«¯ç®¡ç†ï¼Œæ¯æ¬¡è¯·æ±‚æºå¸¦å®Œæ•´å¯¹è¯å†å²ã€‚

**å‚è€ƒé¡¹ç›®**: `reference_repository/nextjs-starter-template` çš„ Chat å®ç°æ¨¡å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
**å®æ–½é˜¶æ®µ**: é˜¶æ®µäºŒï¼ˆåœ¨ RSS è¿ç§»éªŒè¯åå®æ–½ï¼‰

> **ğŸ“– å‰ç½®ä¾èµ–**: è¯·å…ˆå®Œæˆ [11-fastapi-backend-setup.md](./11-fastapi-backend-setup.md) ä¸­çš„åŸºç¡€è®¾æ–½æ­å»ºã€‚

---

## æ¶æ„è®¾è®¡

### æ— çŠ¶æ€ vs æœ‰çŠ¶æ€

| ç‰¹æ€§ | æ— çŠ¶æ€ï¼ˆæœ¬æ–¹æ¡ˆï¼‰ | æœ‰çŠ¶æ€ |
|------|------------------|--------|
| èŠå¤©å†å²å­˜å‚¨ | å‰ç«¯ Context | æ•°æ®åº“ |
| æ•°æ®åº“è¡¨ | æ— éœ€é¢å¤–è¡¨ | chat_sessions, messages |
| è¯·æ±‚ä½“ | åŒ…å«å®Œæ•´å¯¹è¯å†å² | ä»…å½“å‰æ¶ˆæ¯ |
| ä¼šè¯æ¢å¤ | åˆ·æ–°é¡µé¢åä¸¢å¤± | å¯æŒä¹…åŒ– |
| å¤æ‚åº¦ | ä½ | é«˜ |
| é€‚ç”¨åœºæ™¯ | ä¸´æ—¶å¯¹è¯ã€è½»é‡ä½¿ç”¨ | éœ€è¦å†å²è®°å½•çš„åœºæ™¯ |

### æ•°æ®æµ

```
å‰ç«¯ (messages Context)
    â”‚
    â”‚ POST /api/chat/completions
    â”‚ body: { messages: [...], model?: string }
    â”‚
    v
FastAPI /api/chat/completions
    â”‚
    â”‚ 1. éªŒè¯ JWT
    â”‚ 2. è·å–ç”¨æˆ· API é…ç½®
    â”‚ 3. è§£å¯† API å‡­è¯
    â”‚ 4. è°ƒç”¨ LLM (Langchain)
    â”‚
    v
StreamingResponse
    â”‚
    â”‚ 0:"{chunk}"\n (Vercel AI SDK æ ¼å¼)
    â”‚
    v
å‰ç«¯ useChat hook
```

---

## Chat Schemas

```python
# backend/app/schemas/chat.py

from typing import List, Optional, Literal
from pydantic import BaseModel


class ChatMessage(BaseModel):
    """å•æ¡èŠå¤©æ¶ˆæ¯"""
    role: Literal["user", "assistant", "system"]
    content: str


class ChatCompletionRequest(BaseModel):
    """
    Chat å®Œæˆè¯·æ±‚ã€‚

    å‰ç«¯æºå¸¦å®Œæ•´å¯¹è¯å†å²ï¼Œåç«¯æ— çŠ¶æ€å¤„ç†ã€‚
    """
    messages: List[ChatMessage]
    model: Optional[str] = None  # å¯é€‰ï¼šè¦†ç›–é»˜è®¤æ¨¡å‹
    temperature: Optional[float] = 0.7
    max_tokens: Optional[int] = None


class ChatCompletionResponse(BaseModel):
    """éæµå¼å“åº”ï¼ˆå¤‡ç”¨ï¼‰"""
    content: str
    model: str
    usage: Optional[dict] = None
```

---

## Chat Service

æ— çŠ¶æ€ç‰ˆæœ¬çš„ Chat Serviceï¼Œä¸æ¶‰åŠæ•°æ®åº“æ“ä½œï¼š

```python
# backend/app/services/chat_service.py

"""
Chat Service - æ— çŠ¶æ€ LLM æµå¼å¤„ç†

è®¾è®¡: æ— çŠ¶æ€ï¼Œä¸å­˜å‚¨èŠå¤©è®°å½•
æµå¼æ ¼å¼: 0:"{chunk}"\n (Vercel AI SDK Data Stream Protocol)
"""

from typing import List, AsyncGenerator, Optional

from fastapi import HTTPException
from fastapi.responses import StreamingResponse
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from sqlalchemy.orm import Session

from app.schemas.chat import ChatMessage
from app.services.encryption_service import decrypt, is_encrypted


# ============================================
# ç³»ç»Ÿæç¤ºè¯
# ============================================

SYSTEM_TEMPLATE = """You are a helpful assistant that helps users explore and understand their RSS feed content.

You can:
- Answer questions about articles the user has read
- Summarize content from their feeds
- Help discover connections between different articles
- Provide insights and analysis

Be concise, helpful, and accurate. If you don't know something, say so.
When discussing specific articles, reference them clearly."""


# ============================================
# è¾…åŠ©å‡½æ•°
# ============================================

def get_user_api_config(db: Session, user_id: str) -> dict | None:
    """
    è·å–ç”¨æˆ·çš„é»˜è®¤ API é…ç½®ã€‚

    ä¼˜å…ˆçº§:
    1. is_default=True ä¸” is_active=True çš„é…ç½®
    2. ä»»æ„ is_active=True çš„é…ç½®
    """
    # ä½¿ç”¨åŸå§‹ SQL æŸ¥è¯¢ api_configs è¡¨
    from sqlalchemy import text

    # å°è¯•è·å–é»˜è®¤é…ç½®
    result = db.execute(text("""
        SELECT id, name, api_key, api_base, model, is_default, is_active
        FROM api_configs
        WHERE user_id = :user_id AND is_default = true AND is_active = true
        LIMIT 1
    """), {"user_id": user_id}).fetchone()

    if result:
        return {
            "id": str(result[0]),
            "name": result[1],
            "api_key": result[2],
            "api_base": result[3],
            "model": result[4],
            "is_default": result[5],
            "is_active": result[6]
        }

    # å›é€€åˆ°ä»»æ„æ´»è·ƒé…ç½®
    result = db.execute(text("""
        SELECT id, name, api_key, api_base, model, is_default, is_active
        FROM api_configs
        WHERE user_id = :user_id AND is_active = true
        LIMIT 1
    """), {"user_id": user_id}).fetchone()

    if result:
        return {
            "id": str(result[0]),
            "name": result[1],
            "api_key": result[2],
            "api_base": result[3],
            "model": result[4],
            "is_default": result[5],
            "is_active": result[6]
        }

    return None


# ============================================
# æ ¸å¿ƒæµå¼å¤„ç†
# ============================================

async def stream_chat_completion(
    db: Session,
    user_id: str,
    messages: List[ChatMessage],
    model_override: str | None = None,
    temperature: float = 0.7
) -> StreamingResponse:
    """
    å¤„ç†èŠå¤©è¯·æ±‚å¹¶è¿”å›æµå¼å“åº”ï¼ˆæ— çŠ¶æ€ï¼‰ã€‚

    æµå¼æ ¼å¼: Vercel AI SDK Data Stream Protocol
    - æ–‡æœ¬å—: 0:"{chunk}"\n

    Args:
        db: æ•°æ®åº“ä¼šè¯ï¼ˆä»…ç”¨äºè·å– API é…ç½®ï¼‰
        user_id: ç”¨æˆ· ID
        messages: å®Œæ•´å¯¹è¯å†å²ï¼ˆç”±å‰ç«¯æä¾›ï¼‰
        model_override: å¯é€‰æ¨¡å‹è¦†ç›–
        temperature: ç”Ÿæˆæ¸©åº¦

    Returns:
        StreamingResponse: æµå¼å“åº”
    """
    # 1. è·å–ç”¨æˆ· API é…ç½®
    api_config = get_user_api_config(db, user_id)
    if not api_config:
        raise HTTPException(
            status_code=400,
            detail="No API configuration found. Please configure an API in settings."
        )

    # 2. è§£å¯† API å‡­è¯
    api_key = api_config["api_key"]
    api_base = api_config["api_base"]

    if is_encrypted(api_key):
        api_key = decrypt(api_key)
    if is_encrypted(api_base):
        api_base = decrypt(api_base)

    # 3. åˆ›å»º LLM å®¢æˆ·ç«¯
    model_name = model_override or api_config["model"]

    llm = ChatOpenAI(
        model=model_name,
        streaming=True,
        openai_api_key=api_key,
        openai_api_base=api_base,
        temperature=temperature,
    )

    # 4. æ„å»º Langchain æ¶ˆæ¯
    langchain_messages = [("system", SYSTEM_TEMPLATE)]
    for msg in messages:
        langchain_messages.append((msg.role, msg.content))

    prompt = ChatPromptTemplate.from_messages(langchain_messages)
    chain = prompt | llm | StrOutputParser()

    # 5. æµå¼ç”Ÿæˆå™¨ï¼ˆæ— çŠ¶æ€ï¼Œä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
    async def generate() -> AsyncGenerator[str, None]:
        try:
            async for chunk in chain.astream({}):
                # Vercel AI SDK æ•°æ®æµæ ¼å¼
                # è½¬ä¹‰å¼•å·å’Œæ¢è¡Œç¬¦
                escaped = chunk.replace('\\', '\\\\').replace('"', '\\"').replace('\n', '\\n')
                yield f'0:"{escaped}"\n'
        except Exception as e:
            # å‘é€é”™è¯¯ä¿¡æ¯
            error_msg = str(e).replace('"', '\\"')
            yield f'0:"Error: {error_msg}"\n'

    response = StreamingResponse(
        generate(),
        media_type="text/event-stream"
    )

    # æ·»åŠ  Vercel AI SDK éœ€è¦çš„å¤´
    response.headers["x-vercel-ai-data-stream"] = "v1"
    response.headers["Cache-Control"] = "no-cache"
    response.headers["Connection"] = "keep-alive"

    return response
```

---

## Chat API è·¯ç”±

ç®€åŒ–ç‰ˆ Chat APIï¼Œä»…æä¾›æµå¼å®Œæˆç«¯ç‚¹ï¼š

```python
# backend/app/api/routers/chat.py

"""
Chat Router - æ— çŠ¶æ€æµå¼èŠå¤©

è®¾è®¡: æ— çŠ¶æ€ï¼Œä¸å­˜å‚¨èŠå¤©è®°å½•
ç«¯ç‚¹:
- POST /completions - æµå¼èŠå¤©å®Œæˆï¼ˆä¸»ç«¯ç‚¹ï¼‰
"""

from fastapi import APIRouter, Depends
from sqlalchemy.orm import Session

from app.database import get_db
from app.dependencies import get_user_id
from app.schemas.chat import ChatCompletionRequest
from app.services.chat_service import stream_chat_completion

router = APIRouter()


@router.post("/completions")
async def chat_completions(
    request: ChatCompletionRequest,
    user_id: str = Depends(get_user_id),
    db: Session = Depends(get_db)
):
    """
    æµå¼èŠå¤©å®Œæˆï¼ˆæ— çŠ¶æ€ï¼‰ã€‚

    å‰ç«¯æºå¸¦å®Œæ•´å¯¹è¯å†å²ï¼Œåç«¯ä»…å¤„ç†å½“å‰è¯·æ±‚ï¼Œä¸å­˜å‚¨ä»»ä½•æ•°æ®ã€‚

    Request Body:
        - messages: å®Œæ•´å¯¹è¯å†å² [{"role": "user/assistant", "content": "..."}]
        - model: (å¯é€‰) è¦†ç›–é»˜è®¤æ¨¡å‹
        - temperature: (å¯é€‰) ç”Ÿæˆæ¸©åº¦ï¼Œé»˜è®¤ 0.7

    Response:
        StreamingResponse: Vercel AI SDK æ ¼å¼çš„æµå¼å“åº”
        æ ¼å¼: 0:"{chunk}"\n
    """
    return await stream_chat_completion(
        db=db,
        user_id=user_id,
        messages=request.messages,
        model_override=request.model,
        temperature=request.temperature or 0.7
    )
```

---

## æ›´æ–° main.py

åœ¨ FastAPI ä¸»åº”ç”¨ä¸­æ³¨å†Œ Chat è·¯ç”±ï¼š

```python
# backend/app/main.py

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

from app.database import engine, Base
from app.api.routers import rss, chat

# åˆ›å»ºæ‰€æœ‰è¡¨ï¼ˆä¸åŒ…æ‹¬ Chat ç›¸å…³è¡¨ï¼Œå› ä¸ºæ— çŠ¶æ€è®¾è®¡ï¼‰
Base.metadata.create_all(bind=engine)

app = FastAPI(title="RSS Reader API")

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†Œè·¯ç”±
app.include_router(rss.router, prefix="/api/rss", tags=["RSS"])
app.include_router(chat.router, prefix="/api/chat", tags=["Chat"])


@app.get("/health")
def health_check():
    return {"status": "healthy"}
```

---

## å‰ç«¯é›†æˆ

### AuthContext å’Œ Token ç®¡ç†

å‚è€ƒ `nextjs-starter-template/frontend/src/context/AuthContext.tsx`ï¼š

```typescript
// lib/context/auth-context.tsx

"use client"

import { createContext, useContext, useEffect, useState, ReactNode } from "react"
import { User } from "@supabase/supabase-js"
import { supabase } from "@/lib/supabase/client"

interface AuthContextType {
  user: User | null
  loading: boolean
  getToken: () => Promise<string | null>
}

const AuthContext = createContext<AuthContextType>({
  user: null,
  loading: true,
  getToken: async () => null
})

export function AuthProvider({ children }: { children: ReactNode }) {
  const [user, setUser] = useState<User | null>(null)
  const [loading, setLoading] = useState(true)

  useEffect(() => {
    // è·å–åˆå§‹ä¼šè¯
    supabase.auth.getSession().then(({ data: { session } }) => {
      setUser(session?.user ?? null)
      setLoading(false)
    })

    // ç›‘å¬è®¤è¯çŠ¶æ€å˜åŒ–
    const { data: { subscription } } = supabase.auth.onAuthStateChange(
      (_event, session) => {
        setUser(session?.user ?? null)
      }
    )

    return () => subscription.unsubscribe()
  }, [])

  const getToken = async (): Promise<string | null> => {
    const { data: { session } } = await supabase.auth.getSession()
    return session?.access_token ?? null
  }

  return (
    <AuthContext.Provider value={{ user, loading, getToken }}>
      {children}
    </AuthContext.Provider>
  )
}

export const useAuth = () => useContext(AuthContext)
```

### Chat é¡µé¢ç»„ä»¶ï¼ˆç®€åŒ–ç‰ˆï¼‰

```typescript
// app/(reader)/chat/page.tsx

"use client"

import { useEffect, useState, useRef } from "react"
import { useChat } from "ai/react"
import { useAuth } from "@/lib/context/auth-context"

import { ChatMessages } from "@/components/chat/chat-messages"
import { ChatInput } from "@/components/chat/chat-input"

/**
 * Chat é¡µé¢ï¼ˆæ— çŠ¶æ€è®¾è®¡ï¼‰
 *
 * ç‰¹ç‚¹:
 * - ä¸å­˜å‚¨èŠå¤©è®°å½•åˆ°æ•°æ®åº“
 * - èŠå¤©å†å²ç”± useChat hook å†…éƒ¨ç®¡ç†
 * - åˆ·æ–°é¡µé¢åå†å²æ¶ˆæ¯ä¸¢å¤±
 */
export default function ChatPage() {
  const { getToken, user, loading: authLoading } = useAuth()
  const [token, setToken] = useState<string | null>(null)
  const messagesEndRef = useRef<HTMLDivElement>(null)

  // è·å– JWT token
  useEffect(() => {
    if (!authLoading && user) {
      getToken().then(setToken)
    }
  }, [authLoading, user, getToken])

  // useChat hook (Vercel AI SDK)
  const {
    messages,
    input,
    handleInputChange,
    handleSubmit,
    isLoading,
    error
  } = useChat({
    // é€šè¿‡ rewrites è½¬å‘åˆ° FastAPI
    api: "/api/backend/chat/completions",
    headers: token ? { Authorization: `Bearer ${token}` } : {},
    // åŒ¹é…åç«¯çš„ 0:"{chunk}"\n æ ¼å¼
    streamProtocol: "data",
  })

  // è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" })
  }, [messages])

  // è®¤è¯æ£€æŸ¥
  if (authLoading) {
    return (
      <div className="flex h-full items-center justify-center">
        <p className="text-muted-foreground">Loading...</p>
      </div>
    )
  }

  if (!user) {
    return (
      <div className="flex h-full items-center justify-center">
        <p className="text-muted-foreground">Please sign in to use chat.</p>
      </div>
    )
  }

  return (
    <div className="flex h-full flex-col">
      {/* é”™è¯¯æç¤º */}
      {error && (
        <div className="bg-destructive/10 text-destructive px-4 py-2">
          Error: {error.message}
        </div>
      )}

      {/* æ¶ˆæ¯åˆ—è¡¨ */}
      <div className="flex-1 overflow-y-auto p-4">
        <ChatMessages messages={messages} isLoading={isLoading} />
        <div ref={messagesEndRef} />
      </div>

      {/* è¾“å…¥æ¡† */}
      <div className="border-t p-4">
        <ChatInput
          input={input}
          isLoading={isLoading}
          onInputChange={handleInputChange}
          onSubmit={handleSubmit}
        />
      </div>
    </div>
  )
}
```

### Chat ç»„ä»¶ç›®å½•ç»“æ„ï¼ˆç®€åŒ–ç‰ˆï¼‰

```
components/chat/
â”œâ”€â”€ chat-messages.tsx    # æ¶ˆæ¯æ˜¾ç¤ºç»„ä»¶
â”œâ”€â”€ chat-input.tsx       # è¾“å…¥æ¡†ç»„ä»¶
â”œâ”€â”€ chat-message.tsx     # å•æ¡æ¶ˆæ¯ç»„ä»¶
â””â”€â”€ index.ts             # å¯¼å‡º
```

> **ğŸ“ Note**: æ— çŠ¶æ€è®¾è®¡ä¸éœ€è¦ä¼šè¯ä¾§è¾¹æ ç»„ä»¶ã€‚

---

## Next.js Rewrites é…ç½®

ç¡®ä¿ `next.config.js` é…ç½®äº† rewritesï¼š

```javascript
// next.config.js

/** @type {import('next').NextConfig} */
const nextConfig = {
  async rewrites() {
    return [
      {
        source: '/api/backend/:path*',
        destination: 'http://localhost:8000/api/:path*',
      },
    ]
  },
}

module.exports = nextConfig
```

---

## æµ‹è¯• Chat åŠŸèƒ½

### 1. å¯åŠ¨æœåŠ¡

```bash
# ç»ˆç«¯ 1: FastAPI åç«¯
cd backend
poetry run uvicorn app.main:app --reload --port 8000

# ç»ˆç«¯ 2: Next.js å‰ç«¯
pnpm dev
```

### 2. API æµ‹è¯•

```bash
# è·å– JWT tokenï¼ˆä»æµè§ˆå™¨ DevTools å¤åˆ¶ï¼‰
TOKEN="your_supabase_jwt_token"

# æµ‹è¯•æµå¼èŠå¤©
curl -X POST http://localhost:8000/api/chat/completions \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "messages": [
      {"role": "user", "content": "Hello, how are you?"}
    ]
  }'
```

### 3. æµå¼å“åº”éªŒè¯

å‘é€æ¶ˆæ¯ååº”è¯¥çœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„æµå¼è¾“å‡ºï¼š

```
0:"Hello"
0:"!"
0:" I'm"
0:" doing"
0:" well"
0:"."
```

---

## æ•…éšœæ’é™¤

### æµå¼å“åº”ä¸å·¥ä½œ

**æ£€æŸ¥**:
1. ç¡®ä¿ `x-vercel-ai-data-stream: v1` header å­˜åœ¨
2. ç¡®ä¿ä½¿ç”¨ `text/event-stream` content-type
3. ç¡®ä¿ Next.js Rewrites é…ç½®æ­£ç¡®ï¼ˆ`next.config.js`ï¼‰
4. æ£€æŸ¥ FastAPI æ˜¯å¦æ­£åœ¨è¿è¡Œï¼ˆ`http://localhost:8000/health`ï¼‰

> **ğŸ’¡ æç¤º**ï¼šä½¿ç”¨ Next.js Rewrites åï¼Œæ— éœ€æ‹…å¿ƒ CORS é—®é¢˜ã€‚

### API é…ç½®é”™è¯¯

**æ£€æŸ¥**:
1. ç”¨æˆ·æ˜¯å¦æœ‰é…ç½® API Configï¼ˆåœ¨ Settings â†’ API é¡µé¢ï¼‰
2. API Config æ˜¯å¦ `is_active=true`
3. åŠ å¯†çš„å‡­è¯æ˜¯å¦èƒ½æ­£ç¡®è§£å¯†

### è®¤è¯å¤±è´¥

**æ£€æŸ¥**:
1. JWT token æ˜¯å¦æœ‰æ•ˆï¼ˆæœªè¿‡æœŸï¼‰
2. `get_user_id` ä¾èµ–æ˜¯å¦æ­£ç¡®éªŒè¯ token
3. Supabase é¡¹ç›® URL å’Œ anon key æ˜¯å¦æ­£ç¡®é…ç½®

---

## ä¸‹ä¸€æ­¥

å®Œæˆ Chat åŠŸèƒ½åï¼Œç»§ç»­ï¼š

1. **[14-frontend-integration.md](./14-frontend-integration.md)** - å‰ç«¯é›†æˆæŒ‡å—
2. **RAG é›†æˆ** - æ£€ç´¢ RSS æ–‡ç« å†…å®¹å¢å¼ºå›ç­”
3. **è¯­ä¹‰æœç´¢** - åŸºäº pgvector çš„æ–‡ç« æœç´¢

---

## å¯é€‰ï¼šå‡çº§åˆ°æœ‰çŠ¶æ€è®¾è®¡

å¦‚æœæœªæ¥éœ€è¦å­˜å‚¨èŠå¤©è®°å½•ï¼Œå¯ä»¥å‚è€ƒåŸ `nextjs-starter-template` çš„å®ç°ï¼š

1. æ·»åŠ  `chat_sessions` å’Œ `messages` æ•°æ®åº“è¡¨
2. åˆ›å»º `ChatSession` å’Œ `Message` ORM æ¨¡å‹
3. æ‰©å±• Chat Service æ·»åŠ æ¶ˆæ¯ä¿å­˜é€»è¾‘
4. æ‰©å±• API æ·»åŠ ä¼šè¯ CRUD ç«¯ç‚¹
5. å‰ç«¯æ·»åŠ ä¼šè¯åˆ—è¡¨ä¾§è¾¹æ 

å…·ä½“å®ç°å¯å‚è€ƒ `reference_repository/nextjs-starter-template/backend/` ç›®å½•ã€‚
